<!DOCTYPE html><html class="appearance-auto" lang="en"><head><meta charset="UTF-8"><title>è·‘æ·±åº¦å­¦ä¹ ä»£ç æ—¶è‡ªåŠ¨é€‰æ‹©æ˜¾å¡</title><meta name="description" content="çŸ©é˜µä¾ "><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/%E5%A4%B4%E5%83%8F.jpg"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/post.css"><link rel="stylesheet" href="/style/themes/highlight-theme-light.css"><script src="/js/highlight.pack.js"></script><meta name="description" content="
å¼•è¨€é•¿æœŸä»¥æ¥ï¼Œç¬”è€…åœ¨è·‘æ·±åº¦å­¦ä¹ å®éªŒæ—¶ï¼Œæ€»ä¼šé‡åˆ°è¿™æ ·ä¸€ä¸ªé—®é¢˜: ç©¶ç«Ÿè¯¥é€‰å“ªå—(or å“ªå‡ å—)å¡ï¼Ÿå› ä¸ºç¬”è€…ä½¿ç”¨çš„æœåŠ¡å™¨ä¸€å…±æœ‰9å—æ˜¾å¡, æœ‰10ä¸ªäººå¯ä»¥ç”¨ï¼Œæ¯ä¸ªäººéšæœºæ—¶é—´æ®µä½¿ç”¨ã€‚é‚£ä¹ˆå¾ˆå¸¸è§çš„æƒ…å†µå°±æ˜¯, æˆ‘å¤´ä¸€å¤©è·‘è¿‡çš„ä»£ç ï¼Œç¬¬äºŒå¤©å†è·‘çš„æ—¶å€™è¿è¡Œäº†å‡ åˆ†é’Ÿç”šè‡³åæ¥åˆ†é’Ÿåçªç„¶æŠ¥é”™: OOM Errorã€‚ã€‚ã€‚è·Ÿåƒshitäº†ä¸€æ ·éš¾å—ï¼Œæœ€åç°æºœæºœçš„åœ¨ç»ˆç«¯è¾“å…¥nvidia-smi(æˆ‘aliasäº†ä¹Ÿè¿˜æ˜¯æ„Ÿè§‰éº»çƒ¦)ï¼Œç”¨è‚‰çœ¼åˆ†æå“ªå‡ ä¸ªå‰©ä½™æ˜¾å¡å¯ä»¥ç”¨ã€‚å¯¹äºä½¿ç”¨tensorflowçš„åŒå­¦æ¥è¯´ï¼Œå°¤æ˜¯ä¸€åœºç¾éš¾ï¼Œå› ä¸ºtensorflowçš„å‰æ‘‡æ—¶é—´æ¯”pytorchçœŸçš„é•¿äº†ä¸çŸ¥é“å¤šå°‘ã€‚å› æ­¤ï¼Œå¦‚æœèƒ½åœ¨æ¯ä¸ªæ·±åº¦å­¦ä¹ ä»£ç å‰ï¼ŒåŠ ä¸€ä¸ªè‡ªåŠ¨æ£€æµ‹å¯ç”¨æ˜¾å¡ç¨‹åºï¼Œå²‚ä¸æ˜¯èŠ‚çº¦äº†å¾ˆå¤šæ—¶é—´ã€‚
é—®é¢˜æ¢ç©¶1)tryâ€¦ exceptâ€¦
ä¼ªä»£ç 
for cardnumber i.."><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.2.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="MatrixMan's blog" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">Coding Fxxker's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">è·‘æ·±åº¦å­¦ä¹ ä»£ç æ—¶è‡ªåŠ¨é€‰æ‹©æ˜¾å¡</p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">Click back to the top</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%95%E8%A8%80"><span class="toc-text">å¼•è¨€</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E6%8E%A2%E7%A9%B6"><span class="toc-text">é—®é¢˜æ¢ç©¶</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%8E%E8%AE%B0"><span class="toc-text">åè®°</span></a></li></ol></div><div class="column is-9"><header class="my-4"><a href="/tags/%E6%AD%A3%E5%88%99%E5%BC%8F%E5%8C%B9%E9%85%8D"><i class="tag post-item-tag">æ­£åˆ™å¼åŒ¹é…</i></a></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle">è·‘æ·±åº¦å­¦ä¹ ä»£ç æ—¶è‡ªåŠ¨é€‰æ‹©æ˜¾å¡</h1><time class="has-text-grey" datetime="2021-07-22T16:43:08.000Z">2021-07-23</time><article class="mt-2 post-content"><p><img src="/2021/07/23/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%87%AA%E5%8A%A8%E9%80%89%E6%8B%A9%E6%98%BE%E5%8D%A1/%E6%98%BE%E5%8D%A1.jpg"></p>
<h3 id="å¼•è¨€"><a href="#å¼•è¨€" class="headerlink" title="å¼•è¨€"></a>å¼•è¨€</h3><p>é•¿æœŸä»¥æ¥ï¼Œç¬”è€…åœ¨è·‘æ·±åº¦å­¦ä¹ å®éªŒæ—¶ï¼Œæ€»ä¼šé‡åˆ°è¿™æ ·ä¸€ä¸ªé—®é¢˜: ç©¶ç«Ÿè¯¥é€‰å“ªå—(or å“ªå‡ å—)å¡ï¼Ÿ<br>å› ä¸ºç¬”è€…ä½¿ç”¨çš„æœåŠ¡å™¨ä¸€å…±æœ‰9å—æ˜¾å¡, æœ‰10ä¸ªäººå¯ä»¥ç”¨ï¼Œæ¯ä¸ªäººéšæœºæ—¶é—´æ®µä½¿ç”¨ã€‚é‚£ä¹ˆå¾ˆå¸¸è§çš„æƒ…å†µå°±æ˜¯, æˆ‘å¤´ä¸€å¤©è·‘è¿‡çš„ä»£ç ï¼Œç¬¬äºŒå¤©å†è·‘çš„æ—¶å€™è¿è¡Œäº†å‡ åˆ†é’Ÿç”šè‡³åæ¥åˆ†é’Ÿåçªç„¶æŠ¥é”™: OOM Errorã€‚ã€‚ã€‚è·Ÿåƒshitäº†ä¸€æ ·éš¾å—ï¼Œæœ€åç°æºœæºœçš„åœ¨ç»ˆç«¯è¾“å…¥nvidia-smi(æˆ‘aliasäº†ä¹Ÿè¿˜æ˜¯æ„Ÿè§‰éº»çƒ¦)ï¼Œç”¨è‚‰çœ¼åˆ†æå“ªå‡ ä¸ªå‰©ä½™æ˜¾å¡å¯ä»¥ç”¨ã€‚å¯¹äºä½¿ç”¨tensorflowçš„åŒå­¦æ¥è¯´ï¼Œå°¤æ˜¯ä¸€åœºç¾éš¾ï¼Œå› ä¸ºtensorflowçš„å‰æ‘‡æ—¶é—´æ¯”pytorchçœŸçš„é•¿äº†ä¸çŸ¥é“å¤šå°‘ã€‚å› æ­¤ï¼Œå¦‚æœèƒ½åœ¨æ¯ä¸ªæ·±åº¦å­¦ä¹ ä»£ç å‰ï¼ŒåŠ ä¸€ä¸ªè‡ªåŠ¨æ£€æµ‹å¯ç”¨æ˜¾å¡ç¨‹åºï¼Œå²‚ä¸æ˜¯èŠ‚çº¦äº†å¾ˆå¤šæ—¶é—´ã€‚</p>
<h3 id="é—®é¢˜æ¢ç©¶"><a href="#é—®é¢˜æ¢ç©¶" class="headerlink" title="é—®é¢˜æ¢ç©¶"></a>é—®é¢˜æ¢ç©¶</h3><p>1)tryâ€¦ exceptâ€¦</p>
<p>ä¼ªä»£ç </p>
<pre><code class="python">for cardnumber in gpuList:
    try:
        os.environ["CUDA_VISIBLE_DEVICE"] = cardnumber
        run_yourmodel()
    except OOMERROR as e:
        pass</code></pre>
<p>è¿™ä¸ªæ–¹æ¡ˆé—®é¢˜åœ¨äºè¯•é”™æˆæœ¬å¤ªé«˜ã€‚è¯•æƒ³æˆ‘åœ¨ä½¿ç”¨tensorflow, æ¯æ¬¡è¿è¡Œå‰éƒ½ä¼šé¢„å…ˆæ£€æŸ¥æ˜¾å¡çš„å„ç§ä¿¡æ¯ï¼Œç„¶åoomï¼Œç„¶åè¯•ä¸‹ä¸€ä¸ªæ˜¾å¡ï¼Œæ—¶é—´ä¼šçˆ†ç‚¸ã€‚ç”šè‡³é‡åˆ°åˆ†å¸ƒå¼è®­ç»ƒæ—¶å€™ï¼Œæˆ‘éš¾é“è¦åœ¨å€™é€‰æ˜¾å¡åˆ—è¡¨é‡Œï¼Œæ’åˆ—ç»„åˆæ‰€æœ‰çš„æ˜¾å¡ç»„åˆï¼Ÿæ˜¾ç„¶ä¸è¡Œï¼Œå› æ­¤è¿™ä¸ªæ–¹æ¡ˆæ”¾å¼ƒã€‚</p>
<p>2)è·å–æ˜¾å¡ä¿¡æ¯ååŠ è½½<br>åœ¨æˆ‘çš„è®¾æƒ³ä¸­ï¼ŒNvidiaå®˜æ–¹åº”è¯¥æ˜¯ç»™äº†æ§åˆ¶æ¥å£çš„ï¼Œç”¨äºè·å–æ€»çš„memory, å·²ç»ä½¿ç”¨çš„memory, å‰©ä½™çš„memoryã€‚äº‹å®ä¸Š, è¿˜çœŸçš„ç»™äº†<span class="github-emoji"><span>ğŸ˜³</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f633.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span><br><a target="_blank" rel="noopener" href="https://developer.nvidia.com/nvidia-management-library-nvml">Nvidia nvml æ˜¾å¡ç®¡ç†åº“</a><br>è¿™ä¸ªæ˜¯åŸºäºCæ‰©å±•, ä¸è¿‡æœ‰äººè´¡çŒ®äº†py API<br><a target="_blank" rel="noopener" href="https://github.com/gpuopenanalytics/pynvml">Pynvml</a><br>ç¬”è€…åœ¨åŠå¹´å¤šä¹‹å‰æ²¡æœ‰å‘ç°è¿™ä¸ªé¡¹ç›®ï¼Œå½“æ—¶å¼ºè¡Œè§£ænvidia-smiä¿¡æ¯ï¼Œåˆ†æè¿‡ç¨‹å¦‚ä¸‹<br>é¦–å…ˆç”¨pythonæ‰§è¡Œterminalå‘½ä»¤è·å–æ˜¾å¡ä¿¡æ¯</p>
<pre><code class="python">import os
for i in os.popen('nvidia-smi').read():print(i)</code></pre>
<p>è¿”å›</p>
<pre><code>Fri Jul 23 21:05:39 2021
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  TITAN RTX           Off  | 00000000:04:00.0 Off |                  N/A |
| 40%   46C    P8     5W / 280W |     11MiB / 24220MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  TITAN RTX           Off  | 00000000:06:00.0 Off |                  N/A |
| 97%   88C    P2   231W / 280W |  23526MiB / 24220MiB |    100%      Default |
+-------------------------------+----------------------+----------------------+
|   2  TITAN RTX           Off  | 00000000:07:00.0 Off |                  N/A |
| 41%   44C    P8     7W / 280W |     11MiB / 24220MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  TITAN V             Off  | 00000000:08:00.0 Off |                  N/A |
| 34%   49C    P8    29W / 250W |     12MiB / 12066MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   4  TITAN RTX           Off  | 00000000:0B:00.0 Off |                  N/A |
| 41%   44C    P8    15W / 280W |     11MiB / 24220MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   5  TITAN RTX           Off  | 00000000:0C:00.0 Off |                  N/A |
| 41%   46C    P8     9W / 280W |     11MiB / 24220MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   6  TITAN Xp            Off  | 00000000:0D:00.0 Off |                  N/A |
| 23%   39C    P8     9W / 250W |     10MiB / 12196MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   7  TITAN Xp            Off  | 00000000:0E:00.0 Off |                  N/A |
| 25%   44C    P8    10W / 250W |     10MiB / 12196MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   8  TITAN RTX           Off  | 00000000:0F:00.0 Off |                  N/A |
| 41%   46C    P8     1W / 280W |     11MiB / 24220MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    1     61162      C   ...xxx/anaconda3/envs/xxx/bin/python 23515MiB |
+-----------------------------------------------------------------------------+</code></pre>
<p>å°è¯•æŒ‡å®šæ˜¾å¡è¾“å‡º2å·æ˜¾å¡ä¿¡æ¯</p>
<pre><code class="python">import os
for i in os.popen('nvidia-smi -2 1').read().split('\n'):print(i)</code></pre>
<p>è¿”å›</p>
<pre><code>Fri Jul 23 21:10:46 2021
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   2  TITAN RTX           Off  | 00000000:07:00.0 Off |                  N/A |
| 41%   44C    P8     6W / 280W |     11MiB / 24220MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+</code></pre>
<p>é‚£ä¹ˆé—®é¢˜å¾ˆæ¸…æ¥šäº†, æˆ‘ä»¬åœ¨è·å–æŒ‡å®šæ˜¾å¡ä¿¡æ¯åï¼Œéœ€è¦æå–å‡º 11MiB / 24220MiB è¿™ä¸ªå­—æ®µçš„ä¸¤ä¸ªæ•°ã€‚è¿™ä¸ªæ‰‹å†™é€»è¾‘æå–ä¸æ˜¯ä¸å¯ä»¥, ä½†å¹¸å¥½æˆ‘ä»¬æœ‰æ­£åˆ™å¼åŒ¹é…ã€‚</p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/48219401/answer/742444326?utm_source=wechat_session&amp;utm_medium=social&amp;utm_oi=627839486953000960&amp;utm_content=group3_Answer&amp;utm_campaign=shareopn">ç¬”è€…å‚è€ƒçš„æ–‡ç« </a></p>
<pre><code class="python">import os
import re

GPU_state = os.popen('nvidia-smi -i 2').read()
print(re.findall('(\d+)(?=\s*MiB)', GPU_state))#(?=pattern)è¡¨ç¤ºåŒ¹é…patternå‰é¢å†…å®¹
# ç¬¬ä¸€ä¸ª(\d+)è¡¨ç¤ºä»åé¢åŒ¹é…æ¨¡å¼ä¸­ç¬¬äºŒæ¬¡è¿›è¡Œç­›é€‰, åŒ¹é…å¤šä¸ªæ•°å­—å­—ç¬¦
</code></pre>
<p>è¿™é‡Œç®€å•è§£é‡Šä¸€ä¸‹å«ä¹‰ã€‚(?=\s*MiB)ä»£è¡¨åŒ¹é…<strong>å‰é¢æœ‰0æ¬¡æˆ–å¤šæ¬¡ç©ºç™½ç¬¦çš„MiB</strong>è¿™é‡Œå…¶å®\sä¸åŠ ä¹Ÿå¯ä»¥,åªæ˜¯ä¸€ç§é˜²é”™æœºåˆ¶ã€‚ (\d+)è¡¨ç¤ºåŒ¹é…ä¸€æ¬¡æˆ–å¤šæ¬¡æ•°å­—ï¼Œ è¿èµ·æ¥å°±æ˜¯<strong>åŒ¹é…MiBå‰é¢å¤šä¸ªæ•°å­—å­—ç¬¦</strong></p>
<p>è¿”å›</p>
<pre><code>['11', '24220']</code></pre>
<p>è¿™æ­£æ˜¯æˆ‘ä»¬æƒ³è¦çš„ã€‚<br>ä¸‹é¢ç»™å‡ºä¸€ä¸ªè‡ªåŠ¨æ˜¾å¡è·å–ç¨‹åºautoGPU, è¾“å…¥éœ€è¦çš„æ˜¾å¡æ•°, æ¯å¼ å¡éœ€è¦çš„æ˜¾å­˜æ•°, è‡ªåŠ¨é€‰æ‹©æ˜¾å¡ã€‚</p>
<pre><code class="python">def testGPU(id=0, mem_collect='auto'): 
    GPU_state = os.popen('nvidia-smi -i %s' % str(id)).read()
    GPU_type = re.findall('(?=TITAN\s).*?(?=\s+Off)', GPU_state)[0] #è·å–å‹å·
    Usage = re.findall('(\d+)(?=\s*MiB)', GPU_state)[0] #è·å–å·²ä½¿ç”¨æ˜¾å­˜
    Memory = re.findall('(\d+)(?=\s*MiB)', GPU_state)[1] #è·å–æ€»æ˜¾å­˜
    IDLE =  int(Memory) - int(Usage) # è®¡ç®—ç©ºé—²æ˜¾å­˜
    if mem_collect == 'auto': #è‡ªåŠ¨æ¨¡å¼, è·å–å®Œå…¨ç©ºé—²æ˜¾å¡
        if int(Usage) &lt; 20: # è¿™é‡Œå› ä¸ºæœåŠ¡å™¨å¼€äº†gnomeæ¡Œé¢æœåŠ¡, ä¼šæœ‰ä¸åˆ°20MiBæ˜¾å­˜å ç”¨
            return 1, GPU_type, IDLE, int(Memory)
        else:
            return 0, GPU_type, IDLE, int(Memory)

    else:
        if IDLE &gt; mem_collect:
            return 1, GPU_type, IDLE, int(Memory)
        else:
            return 0, GPU_type, IDLE, int(Memory)

def autoGPU(GPU_NUM=6, GPU_MEM='auto'):
    os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID" #å°†æ˜¾å¡è·å–é¡ºåºè°ƒæ•´ä¸ºPCI_BUS_IDæ¨¡å¼,å¦åˆ™å’Œ nvidia-smi ä¸­çš„æ˜¾å¡é¡ºåºä¸ä¸€è‡´
    ID = []
    for i in [8, 5, 4, 2, 1, 0, 3, 7 ,6]: #è‡ªå®šä¹‰äº†ä¸€ä¸ªæ˜¾å¡åºå·è·å–ä¼˜å…ˆçº§é¡ºåº
        is_val, GPU, Usa, Mem = testGPU(i, GPU_MEM) #è¾“å…¥æ˜¾å¡åºå·å’Œéœ€è¦çš„æ˜¾å­˜, ä¾æ¬¡è¿”å›æ˜¯å¦å¯ç”¨, GPUå‹å·, å¯ç”¨æ˜¾å­˜, æ€»å…±æ˜¾å­˜
        if is_val == 1:
            ID.append(str(i))
            print('å·²é€‰æ‹©ç¬¬{}å¼ å¡ï¼Œå‹å·ä¸º{}ï¼Œ{}MB/{}MBæ˜¾å­˜å¯ç”¨'.format(i, GPU, Usa, Mem))
            if len(ID) == GPU_NUM:
                break
    assert len(ID)==GPU_NUM, 'ä½ è¦æ±‚çš„æ˜¾å¡æ¡ä»¶æ— æ³•æ»¡è¶³'
    os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(ID) # è®¾ç½®æ˜¾å¡


if __name__ == '__main__':
    autoGPU(3, 'auto') #è‡ªåŠ¨æ¨¡å¼é€‰æ‹©3å¼ æ˜¾å¡</code></pre>
<p>è¿”å›</p>
<pre><code>å·²é€‰æ‹©ç¬¬8å¼ å¡ï¼Œå‹å·ä¸ºTITAN RTXï¼Œ24209MB/24220MBæ˜¾å­˜å¯ç”¨
å·²é€‰æ‹©ç¬¬5å¼ å¡ï¼Œå‹å·ä¸ºTITAN RTXï¼Œ24209MB/24220MBæ˜¾å­˜å¯ç”¨
å·²é€‰æ‹©ç¬¬4å¼ å¡ï¼Œå‹å·ä¸ºTITAN RTXï¼Œ24209MB/24220MBæ˜¾å­˜å¯ç”¨</code></pre>
<h3 id="åè®°"><a href="#åè®°" class="headerlink" title="åè®°"></a>åè®°</h3><p>è¿™å°æ®µç¨‹åºè¿˜æœ‰å¾ˆå¤šå¯ä»¥æå‡çš„åœ°æ–¹, è¿™é‡ŒåªæŠ›ç –å¼•ç‰ã€‚å¦å¤–å½“æ—¶å†™è¿™ä¸ªç¨‹åºçš„æ—¶å€™æ²¡æœ‰æŸ¥åˆ°Nvidiaå®˜æ–¹æä¾›çš„API, ç°åœ¨çœ‹æ¥è¿˜æ˜¯ç”¨å®˜æ–¹çš„è½®å­å¥½ä¸€ç‚¹ã€‚ä¸è¿‡å› æ­¤å­¦ä¹ äº†ä¸€ç‚¹æ­£åˆ™å¼åŒ¹é…, ä¹Ÿç®—æœ‰ç‚¹æ”¶è·ã€‚</p>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><em></em><a class="button is-default" href="/2021/07/05/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E5%85%AC%E5%BC%80%E6%95%B0%E6%8D%AE%E9%9B%86python%E7%88%AC%E8%99%AB/" title="é›¶åŸºç¡€å¿«é€Ÿæ­å»ºå…¬å¼€æ•°æ®é›†pythonçˆ¬è™«"><span class="has-text-weight-semibold">Next: é›¶åŸºç¡€å¿«é€Ÿæ­å»ºå…¬å¼€æ•°æ®é›†pythonçˆ¬è™«</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container"><script async repo="Haojen/Claudia-theme-blog" src="https://utteranc.es/client.js" issue-term="pathname" theme="preferred-color-scheme"></script></article></div></div></main></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><a title="twitter" target="_blank" rel="noopener nofollow" href="//twitter.com/jmjkx111"><i class="iconfont icon-twitter"></i></a><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/jmjkx"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com/jmjkx"><i class="iconfont icon-ins"></i></a><!-- RSS--><a title="rss" target="_blank" rel="noopener nofollow" href="/atom.xml"><i class="iconfont icon-rss"></i></a><!-- çŸ¥ä¹--><a title="zhihu" target="_blank" rel="noopener nofollow" href="//zhihu.com/people/codefxxker"><i class="iconfont icon-zhihu"></i></a><!-- é¢†è‹±--><!-- è„¸ä¹¦--></section><p><span>Copyright Â©</span><span> Coding Fxxker 2021</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/js/post.js"></script></body></html>